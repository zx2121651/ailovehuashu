import cv2
import mediapipe as mp
import mediapipe.python.solutions as solutions
import numpy as np
import tkinter as tk
from tkinter import filedialog, messagebox
from PIL import Image, ImageTk
import json
import time
import threading
import math

class OneEuroFilter:
    def __init__(self, t0, x0, dx0=0.0, min_cutoff=1.0, beta=0.0, d_cutoff=1.0):
        self.min_cutoff = float(min_cutoff)
        self.beta = float(beta)
        self.d_cutoff = float(d_cutoff)
        self.x_prev = float(x0)
        self.dx_prev = float(dx0)
        self.t_prev = float(t0)

    def smoothing_factor(self, t_e, cutoff):
        r = 2 * math.pi * cutoff * t_e
        return r / (r + 1)

    def exponential_smoothing(self, a, x, x_prev):
        return a * x + (1 - a) * x_prev

    def __call__(self, t, x):
        t_e = t - self.t_prev

        # é¿å…é™¤ä»¥é›¶æˆ–è¿‡å°çš„æ—¶é—´å¢é‡
        if t_e <= 0:
            return x

        # æ ¹æ®æˆªæ­¢é¢‘ç‡å’Œæ—¶é—´æ­¥è®¡ç®—å¹³æ»‘å› å­
        a_d = self.smoothing_factor(t_e, self.d_cutoff)
        dx = (x - self.x_prev) / t_e
        dx_hat = self.exponential_smoothing(a_d, dx, self.dx_prev)

        # æ ¹æ®é€Ÿåº¦è°ƒæ•´æˆªæ­¢é¢‘ç‡
        cutoff = self.min_cutoff + self.beta * abs(dx_hat)
        a = self.smoothing_factor(t_e, cutoff)
        x_hat = self.exponential_smoothing(a, x, self.x_prev)

        # æ›´æ–°çŠ¶æ€
        self.x_prev = x_hat
        self.dx_prev = dx_hat
        self.t_prev = t

        return x_hat

class LandmarkFilter:
    def __init__(self, min_cutoff=1.0, beta=0.0):
        self.min_cutoff = min_cutoff
        self.beta = beta
        self.filters = {} # key: landmark_idx, value: {'x': filter, 'y': filter, 'z': filter}

    def reset(self):
        self.filters.clear()

    def process(self, t, landmarks):
        if not landmarks:
            return None

        smoothed_landmarks = []
        for i, lm in enumerate(landmarks):
            if i not in self.filters:
                self.filters[i] = {
                    'x': OneEuroFilter(t, lm['x'], min_cutoff=self.min_cutoff, beta=self.beta),
                    'y': OneEuroFilter(t, lm['y'], min_cutoff=self.min_cutoff, beta=self.beta),
                    'z': OneEuroFilter(t, lm['z'], min_cutoff=self.min_cutoff, beta=self.beta)
                }
                smoothed_landmarks.append({'x': lm['x'], 'y': lm['y'], 'z': lm['z'], 'v': lm['v']})
            else:
                x = self.filters[i]['x'](t, lm['x'])
                y = self.filters[i]['y'](t, lm['y'])
                z = self.filters[i]['z'](t, lm['z'])
                smoothed_landmarks.append({'x': x, 'y': y, 'z': z, 'v': lm['v']})

        return smoothed_landmarks

class MotionCaptureApp:
    def __init__(self, window, window_title):
        self.window = window
        self.window.title(window_title)
        self.window.geometry("1000x700")

        # è§†é¢‘/æ‘„åƒå¤´ç›¸å…³çŠ¶æ€
        self.vid = None
        self.is_playing = False
        self.video_source = None
        self._update_job = None
        self._canvas_image_id = None

        # MediaPipe åˆå§‹åŒ–
        self.mp_holistic = solutions.holistic
        self.mp_drawing = solutions.drawing_utils
        self.mp_drawing_styles = solutions.drawing_styles
        self.holistic = self.mp_holistic.Holistic(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5,
            model_complexity=1
        )

        # å½•åˆ¶çŠ¶æ€
        self.is_recording = False
        self.recorded_data = []
        self.frame_count = 0
        self.start_time = 0

        # é…ç½®çŠ¶æ€å˜é‡
        self.param_model_complexity = tk.IntVar(value=1)
        self.param_min_det_conf = tk.DoubleVar(value=0.5)
        self.param_min_track_conf = tk.DoubleVar(value=0.5)
        self.param_enable_smoothing = tk.BooleanVar(value=True)
        self.param_smooth_cutoff = tk.DoubleVar(value=1.0)
        self.param_smooth_beta = tk.DoubleVar(value=0.0)

        # æ»¤æ³¢å™¨å®ä¾‹åˆå§‹åŒ–
        self.face_filter = LandmarkFilter(self.param_smooth_cutoff.get(), self.param_smooth_beta.get())
        self.pose_filter = LandmarkFilter(self.param_smooth_cutoff.get(), self.param_smooth_beta.get())
        self.lhand_filter = LandmarkFilter(self.param_smooth_cutoff.get(), self.param_smooth_beta.get())
        self.rhand_filter = LandmarkFilter(self.param_smooth_cutoff.get(), self.param_smooth_beta.get())

        # æ„å»º UI
        self._build_ui()

        # çª—å£å…³é—­äº‹ä»¶
        self.window.protocol("WM_DELETE_WINDOW", self.on_closing)

    def _build_ui(self):
        # ä¸»å¸ƒå±€ï¼šå·¦å³åˆ†æ 
        self.paned_window = tk.PanedWindow(self.window, orient=tk.HORIZONTAL)
        self.paned_window.pack(fill=tk.BOTH, expand=True)

        # å·¦ä¾§ï¼šç”»å¸ƒå’Œåº•éƒ¨çŠ¶æ€æ 
        self.left_frame = tk.Frame(self.paned_window, bg='black')
        self.paned_window.add(self.left_frame, minsize=600)

        self.canvas = tk.Canvas(self.left_frame, bg='black', highlightthickness=0)
        self.canvas.pack(side=tk.TOP, fill=tk.BOTH, expand=True)

        self.status_label = tk.Label(self.left_frame, text="çŠ¶æ€: ç­‰å¾…è¾“å…¥", fg="white", bg="#333", anchor="w", padx=10)
        self.status_label.pack(side=tk.BOTTOM, fill=tk.X)

        # å³ä¾§ï¼šæ§åˆ¶é¢æ¿
        self.right_frame = tk.Frame(self.paned_window, width=350, padx=15, pady=15, bg='#f0f0f0')
        self.paned_window.add(self.right_frame, minsize=350)

        # --- è¾“å…¥æ§åˆ¶åŒº ---
        tk.Label(self.right_frame, text="ã€ è¾“å…¥æºæ§åˆ¶ ã€‘", font=("Arial", 12, "bold"), bg='#f0f0f0').pack(pady=(0, 10))
        btn_frame = tk.Frame(self.right_frame, bg='#f0f0f0')
        btn_frame.pack(fill=tk.X)

        self.btn_camera = tk.Button(btn_frame, text="æ‰“å¼€æ‘„åƒå¤´", command=self.open_camera)
        self.btn_camera.pack(side=tk.LEFT, expand=True, fill=tk.X, padx=2)

        self.btn_video = tk.Button(btn_frame, text="é€‰æ‹©æœ¬åœ°è§†é¢‘", command=self.open_video_file)
        self.btn_video.pack(side=tk.LEFT, expand=True, fill=tk.X, padx=2)

        self.btn_toggle = tk.Button(self.right_frame, text="å¼€å§‹/æš‚åœç”»é¢", command=self.toggle_play, state=tk.DISABLED, pady=5)
        self.btn_toggle.pack(fill=tk.X, pady=(5, 15))

        # --- å¢å¼ºæ•æ‰å‚æ•°é…ç½®åŒº ---
        tk.Label(self.right_frame, text="ã€ æ•æ‰å¼•æ“é…ç½® ã€‘", font=("Arial", 12, "bold"), bg='#f0f0f0').pack(pady=(10, 5))

        # 1. æ¨¡å‹å¤æ‚åº¦
        tk.Label(self.right_frame, text="MediaPipe æ¨¡å‹å¤æ‚åº¦ (é«˜ç²¾åº¦=æ…¢)", bg='#f0f0f0', anchor="w").pack(fill=tk.X)
        complex_frame = tk.Frame(self.right_frame, bg='#f0f0f0')
        complex_frame.pack(fill=tk.X, pady=2)
        tk.Radiobutton(complex_frame, text="0(å¿«)", variable=self.param_model_complexity, value=0, command=self.reinit_holistic, bg='#f0f0f0').pack(side=tk.LEFT)
        tk.Radiobutton(complex_frame, text="1(ä¸­)", variable=self.param_model_complexity, value=1, command=self.reinit_holistic, bg='#f0f0f0').pack(side=tk.LEFT)
        tk.Radiobutton(complex_frame, text="2(å‡†)", variable=self.param_model_complexity, value=2, command=self.reinit_holistic, bg='#f0f0f0').pack(side=tk.LEFT)

        # 2. ç½®ä¿¡åº¦é˜ˆå€¼
        tk.Label(self.right_frame, text="æ£€æµ‹ç½®ä¿¡åº¦ (min_detection_confidence)", bg='#f0f0f0', anchor="w").pack(fill=tk.X, pady=(5, 0))
        det_scale = tk.Scale(self.right_frame, variable=self.param_min_det_conf, from_=0.1, to_=0.9, resolution=0.1, orient=tk.HORIZONTAL, bg='#f0f0f0')
        det_scale.bind("<ButtonRelease-1>", lambda e: self.reinit_holistic())
        det_scale.pack(fill=tk.X)

        tk.Label(self.right_frame, text="è¿½è¸ªç½®ä¿¡åº¦ (min_tracking_confidence)", bg='#f0f0f0', anchor="w").pack(fill=tk.X)
        trk_scale = tk.Scale(self.right_frame, variable=self.param_min_track_conf, from_=0.1, to_=0.9, resolution=0.1, orient=tk.HORIZONTAL, bg='#f0f0f0')
        trk_scale.bind("<ButtonRelease-1>", lambda e: self.reinit_holistic())
        trk_scale.pack(fill=tk.X)

        # --- é˜²æŠ–æ»¤æ³¢é…ç½®åŒº ---
        tk.Label(self.right_frame, text="ã€ OneEuro é˜²æŠ–æ»¤æ³¢ (å¯¼å‡ºæ•°æ®) ã€‘", font=("Arial", 12, "bold"), bg='#f0f0f0').pack(pady=(15, 5))

        tk.Checkbutton(self.right_frame, text="å¯ç”¨ 3D åæ ‡æ•°æ®å¹³æ»‘é˜²æŠ–", variable=self.param_enable_smoothing, bg='#f0f0f0', command=self.update_filter_params).pack(anchor="w")

        tk.Label(self.right_frame, text="æœ€å°æˆªæ­¢é¢‘ç‡ (Min Cutoff) - è¶Šå°è¶Šå¹³æ»‘ä½†æœ‰å»¶è¿Ÿ", bg='#f0f0f0', anchor="w").pack(fill=tk.X, pady=(5, 0))
        cutoff_scale = tk.Scale(self.right_frame, variable=self.param_smooth_cutoff, from_=0.01, to_=5.0, resolution=0.1, orient=tk.HORIZONTAL, bg='#f0f0f0')
        cutoff_scale.bind("<ButtonRelease-1>", lambda e: self.update_filter_params())
        cutoff_scale.pack(fill=tk.X)

        tk.Label(self.right_frame, text="é€Ÿåº¦ç³»æ•° (Beta) - è¶Šå¤§å¯¹å¿«é€Ÿè¿åŠ¨å“åº”è¶Šå¿«", bg='#f0f0f0', anchor="w").pack(fill=tk.X)
        beta_scale = tk.Scale(self.right_frame, variable=self.param_smooth_beta, from_=0.0, to_=2.0, resolution=0.01, orient=tk.HORIZONTAL, bg='#f0f0f0')
        beta_scale.bind("<ButtonRelease-1>", lambda e: self.update_filter_params())
        beta_scale.pack(fill=tk.X)

        # --- å½•åˆ¶å¯¼å‡ºåŒº ---
        tk.Frame(self.right_frame, height=2, bd=1, relief=tk.SUNKEN).pack(fill=tk.X, pady=15)
        tk.Label(self.right_frame, text="ã€ æ•°æ®æ•æ‰å½•åˆ¶ ã€‘", font=("Arial", 12, "bold"), bg='#f0f0f0').pack(pady=(0, 10))

        self.btn_record = tk.Button(self.right_frame, text="ğŸ”´ å¼€å§‹å½•åˆ¶ (å¯¼å‡ºå¹³æ»‘ JSON)", command=self.toggle_record, state=tk.DISABLED, bg='#e0e0e0', font=("Arial", 11, "bold"), pady=10)
        self.btn_record.pack(fill=tk.X)

    def update_filter_params(self):
        cutoff = self.param_smooth_cutoff.get()
        beta = self.param_smooth_beta.get()
        self.face_filter.min_cutoff = cutoff
        self.face_filter.beta = beta
        self.pose_filter.min_cutoff = cutoff
        self.pose_filter.beta = beta
        self.lhand_filter.min_cutoff = cutoff
        self.lhand_filter.beta = beta
        self.rhand_filter.min_cutoff = cutoff
        self.rhand_filter.beta = beta

    def reinit_holistic(self):
        if hasattr(self, 'holistic') and self.holistic is not None:
            self.holistic.close()

        self.holistic = self.mp_holistic.Holistic(
            min_detection_confidence=self.param_min_det_conf.get(),
            min_tracking_confidence=self.param_min_track_conf.get(),
            model_complexity=self.param_model_complexity.get()
        )
        self.status_label.config(text=f"çŠ¶æ€: æ¨¡å‹å·²é‡ç½® (å¤æ‚={self.param_model_complexity.get()})")

    def open_camera(self):
        self._start_video_source(0)
        self.status_label.config(text="çŠ¶æ€: æ‘„åƒå¤´å¼€å¯")

    def open_video_file(self):
        file_path = filedialog.askopenfilename(
            title="é€‰æ‹©è§†é¢‘æ–‡ä»¶",
            filetypes=(("Video files", "*.mp4 *.avi *.mov *.mkv"), ("All files", "*.*"))
        )
        if file_path:
            self._start_video_source(file_path)
            self.status_label.config(text=f"çŠ¶æ€: æ’­æ”¾æœ¬åœ°è§†é¢‘ ({file_path.split('/')[-1]})")

    def _start_video_source(self, source):
        if self.vid is not None:
            self.vid.release()

        if self._update_job is not None:
            self.window.after_cancel(self._update_job)
            self._update_job = None

        self.video_source = source
        self.vid = cv2.VideoCapture(source)

        if not self.vid.isOpened():
            messagebox.showerror("é”™è¯¯", "æ— æ³•æ‰“å¼€è§†é¢‘æº")
            return

        self.is_playing = True
        self.btn_toggle.config(state=tk.NORMAL)
        self.btn_record.config(state=tk.NORMAL)

        # å¯åŠ¨æ›´æ–°å¾ªç¯
        self.update()

    def toggle_play(self):
        self.is_playing = not self.is_playing
        if self.is_playing:
            if self._update_job is not None:
                self.window.after_cancel(self._update_job)
            self.update()
        else:
            if self._update_job is not None:
                self.window.after_cancel(self._update_job)
                self._update_job = None

    def toggle_record(self):
        if not self.is_recording:
            # å¼€å§‹å½•åˆ¶
            self.is_recording = True
            self.recorded_data = []
            self.frame_count = 0
            self.start_time = time.time()
            self.btn_record.config(text="åœæ­¢å½•åˆ¶å¹¶å¯¼å‡º", bg='red', fg='white')
            self.status_label.config(text="çŠ¶æ€: å½•åˆ¶ä¸­...", fg="red")
        else:
            # åœæ­¢å½•åˆ¶å¹¶å¯¼å‡º
            self.is_recording = False
            self.btn_record.config(text="å¼€å§‹å½•åˆ¶ (JSON)", bg='lightgray', fg='black')
            self.status_label.config(text="çŠ¶æ€: å½•åˆ¶åœæ­¢ï¼Œæ­£åœ¨å¯¼å‡º...", fg="blue")
            self.export_data()

    def export_data(self):
        if not self.recorded_data:
            messagebox.showinfo("æç¤º", "æ²¡æœ‰æ•æ‰åˆ°ä»»ä½•æ•°æ®")
            self.status_label.config(text="çŠ¶æ€: å‡†å¤‡å°±ç»ª")
            return

        save_path = filedialog.asksaveasfilename(
            defaultextension=".json",
            initialfile=f"motion_capture_{int(time.time())}.json",
            title="ä¿å­˜æ•æ‰æ•°æ®",
            filetypes=(("JSON files", "*.json"), ("All files", "*.*"))
        )

        if save_path:
            try:
                with open(save_path, 'w', encoding='utf-8') as f:
                    json.dump({
                        "frames": self.frame_count,
                        "fps": self.frame_count / (time.time() - self.start_time),
                        "data": self.recorded_data
                    }, f)
                messagebox.showinfo("æˆåŠŸ", f"æ•°æ®å·²æˆåŠŸå¯¼å‡ºè‡³:\n{save_path}")
            except Exception as e:
                messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºæ•°æ®å¤±è´¥:\n{str(e)}")

        self.status_label.config(text="çŠ¶æ€: å‡†å¤‡å°±ç»ª")

    def _extract_landmarks(self, landmark_list):
        """å°† MediaPipe çš„ landmarks è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨ï¼Œæå– x, y, z å’Œå¯è§åº¦"""
        if not landmark_list:
            return None
        return [{"x": lm.x, "y": lm.y, "z": lm.z, "v": lm.visibility} for lm in landmark_list.landmark]

    def process_frame(self, frame):
        """ä½¿ç”¨ MediaPipe Holistic å¤„ç†è§†é¢‘å¸§"""
        # å°† BGR è½¬æ¢ä¸º RGB
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        image.flags.writeable = False

        # æ‰§è¡Œæ£€æµ‹
        results = self.holistic.process(image)

        image.flags.writeable = True
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

        # åœ¨å›¾åƒä¸Šç»˜åˆ¶ç‰¹å¾ç‚¹
        # 1. é¢éƒ¨ç½‘æ ¼
        self.mp_drawing.draw_landmarks(
            image,
            results.face_landmarks,
            self.mp_holistic.FACEMESH_TESSELATION,
            landmark_drawing_spec=None,
            connection_drawing_spec=self.mp_drawing_styles.get_default_face_mesh_tesselation_style()
        )
        # 2. å§¿æ€ï¼ˆéª¨éª¼ï¼‰
        self.mp_drawing.draw_landmarks(
            image,
            results.pose_landmarks,
            self.mp_holistic.POSE_CONNECTIONS,
            landmark_drawing_spec=self.mp_drawing_styles.get_default_pose_landmarks_style()
        )
        # 3. å·¦æ‰‹
        self.mp_drawing.draw_landmarks(
            image,
            results.left_hand_landmarks,
            self.mp_holistic.HAND_CONNECTIONS
        )
        # 4. å³æ‰‹
        self.mp_drawing.draw_landmarks(
            image,
            results.right_hand_landmarks,
            self.mp_holistic.HAND_CONNECTIONS
        )

        # æå–å…³é”®ç‚¹å¹¶å¹³æ»‘å¤„ç†
        t = time.time()
        raw_face = self._extract_landmarks(results.face_landmarks)
        raw_pose = self._extract_landmarks(results.pose_landmarks)
        raw_lhand = self._extract_landmarks(results.left_hand_landmarks)
        raw_rhand = self._extract_landmarks(results.right_hand_landmarks)

        if self.param_enable_smoothing.get():
            face_data = self.face_filter.process(t, raw_face)
            pose_data = self.pose_filter.process(t, raw_pose)
            lhand_data = self.lhand_filter.process(t, raw_lhand)
            rhand_data = self.rhand_filter.process(t, raw_rhand)
        else:
            face_data, pose_data, lhand_data, rhand_data = raw_face, raw_pose, raw_lhand, raw_rhand

        # å½•åˆ¶æ•°æ® (æ­¤æ—¶è®°å½•çš„ä¸ºå¹³æ»‘åçš„æ•°æ®)
        if self.is_recording:
            frame_data = {
                "frame_id": self.frame_count,
                "timestamp": t - self.start_time,
                "face": face_data,
                "pose": pose_data,
                "left_hand": lhand_data,
                "right_hand": rhand_data
            }
            self.recorded_data.append(frame_data)
            self.frame_count += 1

        return image

    def update(self):
        if self.is_playing and self.vid is not None and self.vid.isOpened():
            ret, frame = self.vid.read()
            if ret:
                # å¤„ç†å›¾åƒ
                processed_frame = self.process_frame(frame)

                # è½¬æ¢å›¾åƒä»¥ä¾¿åœ¨ Tkinter ä¸­æ˜¾ç¤º
                cv2image = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)

                # è°ƒæ•´å›¾åƒå¤§å°ä»¥é€‚åº” Canvas
                h, w = cv2image.shape[:2]
                canvas_w = self.canvas.winfo_width()
                canvas_h = self.canvas.winfo_height()

                if canvas_w > 10 and canvas_h > 10:
                    ratio = min(canvas_w/w, canvas_h/h)
                    new_w, new_h = int(w*ratio), int(h*ratio)
                    cv2image = cv2.resize(cv2image, (new_w, new_h))

                img = Image.fromarray(cv2image)
                self.photo = ImageTk.PhotoImage(image=img)

                if self._canvas_image_id is None:
                    self._canvas_image_id = self.canvas.create_image(canvas_w//2, canvas_h//2, image=self.photo, anchor=tk.CENTER)
                else:
                    self.canvas.itemconfig(self._canvas_image_id, image=self.photo)
                    self.canvas.coords(self._canvas_image_id, canvas_w//2, canvas_h//2)

                # å¾ªç¯è°ƒç”¨
                self._update_job = self.window.after(15, self.update)
            else:
                # è§†é¢‘ç»“æŸ
                if isinstance(self.video_source, str):  # å¦‚æœæ˜¯æœ¬åœ°è§†é¢‘
                    self.is_playing = False
                    if self.is_recording:
                        self.toggle_record()  # è‡ªåŠ¨åœæ­¢å½•åˆ¶å¹¶ä¿å­˜
                    self.status_label.config(text="çŠ¶æ€: è§†é¢‘æ’­æ”¾ç»“æŸ")
                else:
                    self._update_job = self.window.after(15, self.update)

    def on_closing(self):
        if self.is_recording:
            if messagebox.askokcancel("é€€å‡º", "æ­£åœ¨å½•åˆ¶ä¸­ï¼Œé€€å‡ºå°†ä¸¢å¤±å½“å‰æœªä¿å­˜çš„æ•æ‰æ•°æ®ã€‚ç¡®å®šè¦é€€å‡ºå—ï¼Ÿ"):
                self._cleanup_and_quit()
        else:
            self._cleanup_and_quit()

    def _cleanup_and_quit(self):
        self.is_playing = False
        if self._update_job is not None:
            self.window.after_cancel(self._update_job)
        if self.vid is not None:
            self.vid.release()
        self.holistic.close()
        self.window.destroy()

if __name__ == "__main__":
    root = tk.Tk()
    app = MotionCaptureApp(root, "å…¨èº«/é¢éƒ¨ 2Dè½¬3D åŠ¨ç”»æ•æ‰ç³»ç»Ÿ")
    root.mainloop()
